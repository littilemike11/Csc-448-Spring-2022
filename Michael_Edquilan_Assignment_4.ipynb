{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Pyolite",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#author : Michael Edquilan",
      "metadata": {
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nfrom sklearn import datasets # import iris dataset\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn import svm # used for support vector machine\nfrom sklearn.neural_network import MLPClassifier # import neural net\nfrom sklearn.neighbors import KNeighborsClassifier # import KNN\nfrom sklearn.model_selection import cross_val_score",
      "metadata": {
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# import the Iris data set\niris = datasets.load_iris()\nX = iris.data\nY = iris.target",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# setup Iris feature lablels\nIrisF=(\"sepal length (cm)\", \"sepal width (cm)\", \"petal length (cm)\", \"petal width (cm)\")\nfor i in range(0,4):\n    print(IrisF[i])\nfor i in range(3):\n    IrisC = ('Setosa','Versicolor','Virginica')\n    print(IrisC[i])",
      "metadata": {
        "trusted": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "text": "sepal length (cm)\nsepal width (cm)\npetal length (cm)\npetal width (cm)\nSetosa\nVersicolor\nVirginica\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# split data into test(10%) and train (90%)\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.10, random_state = 1)\nX_train\nY_train\nX_test\nY_test\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "## Logistic Regression",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#LOGISTIC REGRESSION ORIGINAL\nclf = LogisticRegression(random_state=0, max_iter= 10000)\nclf.fit(X, Y)\nclf.score(X, Y)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.9733333333333334"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "#LOGISTIC REGRESSION SPLIT\nclf = LogisticRegression(random_state=0, max_iter = 10000)\nclf.fit(X_train, Y_train)\nclf.score(X_test, Y_test)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "1.0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "#probability of sample data points\nclf.predict_proba(X_test)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[9.86391118e-01, 1.36088748e-02, 7.13228564e-09],\n       [2.78650159e-01, 7.19628828e-01, 1.72101311e-03],\n       [5.76552450e-03, 9.07534112e-01, 8.67003631e-02],\n       [9.86900514e-01, 1.30994649e-02, 2.14803367e-08],\n       [8.55060810e-07, 1.89035893e-02, 9.81095556e-01],\n       [4.17249158e-03, 6.87264310e-01, 3.08563198e-01],\n       [1.23630754e-04, 1.21561379e-01, 8.78314990e-01],\n       [9.58274395e-01, 4.17251455e-02, 4.59132966e-07],\n       [9.71270277e-01, 2.87296087e-02, 1.14122304e-07],\n       [7.46061719e-06, 2.56066327e-02, 9.74385907e-01],\n       [1.73123087e-02, 9.06018738e-01, 7.66689532e-02],\n       [9.68017798e-01, 3.19820408e-02, 1.61101107e-07],\n       [3.42142048e-06, 2.82410444e-02, 9.71755534e-01],\n       [6.50979935e-03, 8.39097123e-01, 1.54393077e-01],\n       [6.41032431e-03, 7.91046458e-01, 2.02543217e-01]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "coef =clf.coef_\ncoef\n#each column is a feature, each row is the different class of iris",
      "metadata": {
        "trusted": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[-0.44138155,  0.85881902, -2.4551124 , -0.99800215],\n       [ 0.55096767, -0.31907664, -0.17530765, -0.93548914],\n       [-0.10958613, -0.53974238,  2.63042005,  1.93349129]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "intercept=clf.intercept_\nintercept\n#each column is a seperate class",
      "metadata": {
        "trusted": true
      },
      "execution_count": 10,
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([  9.94655972,   1.87091777, -11.8174775 ])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "#equation of different iris classes \nfor i in range(3):\n    print (IrisC[i],\" : \", coef[i][0],\"x1 + \", coef[i][1],\"x2 + \", coef[i][2],\"x3 + \", coef[i][3],\"x4 + \", intercept[i])   ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "text": "Setosa  :  -0.4413815450567822 x1 +  0.8588190168117873 x2 +  -2.4551123983410412 x3 +  -0.9980021522808156 x4 +  9.946559724066795\nVersicolor  :  0.5509676721290918 x1 +  -0.3190766368082094 x2 +  -0.17530765268505535 x3 +  -0.9354891353279474 x4 +  1.8709177713103367\nVirginica  :  -0.10958612707232307 x1 +  -0.5397423800035863 x2 +  2.630420051026092 x3 +  1.933491287608762 x4 +  -11.817477495377219\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "We got a score of 1.0 on the logistic regression model. This means that the model did a perfect job at classifying the different iris classes given the different feature values. The score measures the percent of times it correctly predicted a iris' class.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Support Vector Machine",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# SUPPORT VECTOR MACHINE ORIGINAL\nclf = svm.SVC()\nclf.fit(X, Y)\nclf.score(X, Y)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 12,
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.9733333333333334"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# SUPPORT VECTOR MACHINE SPLIT\nclf = svm.SVC()\nclf.probability=True\nclf.fit(X_train, Y_train)\nclf.score(X_test, Y_test)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 13,
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "1.0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# prediction of sample data points\nclf.predict_proba(X_test)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 14,
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[0.97595187, 0.01396584, 0.01008229],\n       [0.11040119, 0.86874662, 0.02085219],\n       [0.00758756, 0.96771746, 0.02469499],\n       [0.97438073, 0.01583952, 0.00977974],\n       [0.01717648, 0.00482126, 0.97800226],\n       [0.00844412, 0.80612238, 0.1854335 ],\n       [0.01062964, 0.04064819, 0.94872217],\n       [0.93766625, 0.04702299, 0.01531076],\n       [0.96053072, 0.02845371, 0.01101556],\n       [0.00802901, 0.00313669, 0.98883431],\n       [0.00670412, 0.97858268, 0.0147132 ],\n       [0.95255555, 0.03397369, 0.01347076],\n       [0.00828946, 0.00275113, 0.98895941],\n       [0.00752138, 0.93840971, 0.0540689 ],\n       [0.00590193, 0.91663635, 0.07746172]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "We got a score of 1.0 on the support vector machine model. This means that the model did a perfect job at classifying the different iris classes given the different feature values. The score measures the percent of times it correctly predicted a iris' class. Meaning that it classified all the sample correctly.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Neural Network",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# NEURAL NETWORK ORIGINAL\nmax_score = 0\nmaxi =0\nmaxj=0\nfor i in range(1,11): # test \n    for j in range(1,11):\n        clf = MLPClassifier(solver='lbfgs', alpha=1e-4, hidden_layer_sizes=(i, j), random_state=0, max_iter = 10000)\n        clf.fit(X,Y)\n        score =clf.score(X,Y)\n        if score > max_score:\n            max_score = score\n            maxi =i\n            maxj =j\n        if score > .95:\n            print(\"Hidden layer size : (\",i, \",\", j, \"), : score = \",score)                \nprint(\"Best Hidden layer size : (\",maxi, \",\", maxj, \"), : score = \",max_score) ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 15,
      "outputs": [
        {
          "name": "stdout",
          "text": "Hidden layer size : ( 1 , 2 ), : score =  0.9933333333333333\nHidden layer size : ( 1 , 3 ), : score =  0.9866666666666667\nHidden layer size : ( 1 , 6 ), : score =  0.9933333333333333\nHidden layer size : ( 1 , 8 ), : score =  0.9866666666666667\nHidden layer size : ( 2 , 2 ), : score =  0.9866666666666667\nHidden layer size : ( 2 , 3 ), : score =  0.9866666666666667\nHidden layer size : ( 2 , 4 ), : score =  0.9866666666666667\nHidden layer size : ( 2 , 5 ), : score =  0.9866666666666667\nHidden layer size : ( 2 , 6 ), : score =  0.9866666666666667\nHidden layer size : ( 2 , 7 ), : score =  0.9866666666666667\nHidden layer size : ( 2 , 8 ), : score =  0.9866666666666667\nHidden layer size : ( 2 , 9 ), : score =  0.9866666666666667\nHidden layer size : ( 2 , 10 ), : score =  0.9866666666666667\nHidden layer size : ( 3 , 2 ), : score =  0.9866666666666667\nHidden layer size : ( 3 , 3 ), : score =  0.9866666666666667\nHidden layer size : ( 3 , 4 ), : score =  0.9866666666666667\nHidden layer size : ( 3 , 5 ), : score =  0.9866666666666667\nHidden layer size : ( 3 , 6 ), : score =  0.9866666666666667\nHidden layer size : ( 3 , 7 ), : score =  0.9866666666666667\nHidden layer size : ( 3 , 8 ), : score =  0.9866666666666667\nHidden layer size : ( 3 , 9 ), : score =  0.9733333333333334\nHidden layer size : ( 3 , 10 ), : score =  0.9866666666666667\nHidden layer size : ( 4 , 3 ), : score =  0.9866666666666667\nHidden layer size : ( 4 , 4 ), : score =  0.9866666666666667\nHidden layer size : ( 4 , 5 ), : score =  0.9866666666666667\nHidden layer size : ( 4 , 6 ), : score =  0.9866666666666667\nHidden layer size : ( 4 , 7 ), : score =  0.9866666666666667\nHidden layer size : ( 4 , 8 ), : score =  0.9866666666666667\nHidden layer size : ( 4 , 9 ), : score =  0.9866666666666667\nHidden layer size : ( 4 , 10 ), : score =  0.9866666666666667\nHidden layer size : ( 5 , 3 ), : score =  0.9866666666666667\nHidden layer size : ( 5 , 4 ), : score =  0.9933333333333333\nHidden layer size : ( 5 , 5 ), : score =  0.9933333333333333\nHidden layer size : ( 5 , 6 ), : score =  0.9866666666666667\nHidden layer size : ( 5 , 7 ), : score =  0.9866666666666667\nHidden layer size : ( 5 , 8 ), : score =  0.9866666666666667\nHidden layer size : ( 5 , 9 ), : score =  0.9866666666666667\nHidden layer size : ( 6 , 2 ), : score =  0.9866666666666667\nHidden layer size : ( 6 , 4 ), : score =  0.9933333333333333\nHidden layer size : ( 6 , 6 ), : score =  0.9866666666666667\nHidden layer size : ( 6 , 7 ), : score =  0.9866666666666667\nHidden layer size : ( 6 , 8 ), : score =  0.9866666666666667\nHidden layer size : ( 6 , 10 ), : score =  0.9866666666666667\nHidden layer size : ( 7 , 3 ), : score =  0.9933333333333333\nHidden layer size : ( 7 , 4 ), : score =  0.9866666666666667\nHidden layer size : ( 7 , 5 ), : score =  0.9866666666666667\nHidden layer size : ( 7 , 6 ), : score =  0.98\nHidden layer size : ( 7 , 7 ), : score =  0.9866666666666667\nHidden layer size : ( 7 , 8 ), : score =  0.9866666666666667\nHidden layer size : ( 7 , 9 ), : score =  0.9933333333333333\nHidden layer size : ( 7 , 10 ), : score =  0.9866666666666667\nHidden layer size : ( 8 , 4 ), : score =  0.98\nHidden layer size : ( 8 , 6 ), : score =  0.9933333333333333\nHidden layer size : ( 8 , 9 ), : score =  0.9866666666666667\nHidden layer size : ( 8 , 10 ), : score =  0.9866666666666667\nHidden layer size : ( 9 , 4 ), : score =  0.98\nHidden layer size : ( 9 , 6 ), : score =  0.9866666666666667\nHidden layer size : ( 9 , 8 ), : score =  0.9933333333333333\nHidden layer size : ( 10 , 4 ), : score =  0.9866666666666667\nHidden layer size : ( 10 , 5 ), : score =  0.9866666666666667\nHidden layer size : ( 10 , 7 ), : score =  0.9866666666666667\nHidden layer size : ( 10 , 8 ), : score =  0.9933333333333333\nHidden layer size : ( 10 , 9 ), : score =  0.9866666666666667\nHidden layer size : ( 10 , 10 ), : score =  0.9866666666666667\nBest Hidden layer size : ( 1 , 2 ), : score =  0.9933333333333333\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# NEURAL NETWORK SPLIT\nmax_score = 0\nmaxi =0\nmaxj=0\nfor i in range(1,11): # test \n    for j in range(1,11):\n        clf = MLPClassifier(solver='lbfgs', alpha=1e-4, hidden_layer_sizes=(i, j), random_state=0, max_iter = 10000)\n        clf.fit(X_train,Y_train)\n        score =clf.score(X_test,Y_test)\n        if score > max_score:\n            max_score = score\n            maxi =i\n            maxj =j\n        if score > .95:\n            print(\"Hidden layer size : (\",i, \",\", j, \"), : score = \",score)    \nprint(\"Best Hidden layer size : (\",maxi, \",\", maxj, \"), : score = \",max_score) ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "text": "Hidden layer size : ( 1 , 2 ), : score =  1.0\nHidden layer size : ( 1 , 3 ), : score =  1.0\nHidden layer size : ( 1 , 6 ), : score =  1.0\nHidden layer size : ( 1 , 8 ), : score =  1.0\nHidden layer size : ( 2 , 2 ), : score =  1.0\nHidden layer size : ( 2 , 3 ), : score =  1.0\nHidden layer size : ( 2 , 4 ), : score =  1.0\nHidden layer size : ( 2 , 5 ), : score =  1.0\nHidden layer size : ( 2 , 6 ), : score =  1.0\nHidden layer size : ( 2 , 7 ), : score =  1.0\nHidden layer size : ( 2 , 8 ), : score =  1.0\nHidden layer size : ( 2 , 9 ), : score =  1.0\nHidden layer size : ( 2 , 10 ), : score =  1.0\nHidden layer size : ( 3 , 2 ), : score =  1.0\nHidden layer size : ( 3 , 3 ), : score =  1.0\nHidden layer size : ( 3 , 4 ), : score =  1.0\nHidden layer size : ( 3 , 5 ), : score =  1.0\nHidden layer size : ( 3 , 6 ), : score =  1.0\nHidden layer size : ( 3 , 7 ), : score =  1.0\nHidden layer size : ( 3 , 8 ), : score =  1.0\nHidden layer size : ( 3 , 10 ), : score =  1.0\nHidden layer size : ( 4 , 2 ), : score =  1.0\nHidden layer size : ( 4 , 3 ), : score =  1.0\nHidden layer size : ( 4 , 4 ), : score =  1.0\nHidden layer size : ( 4 , 5 ), : score =  1.0\nHidden layer size : ( 4 , 6 ), : score =  1.0\nHidden layer size : ( 4 , 7 ), : score =  1.0\nHidden layer size : ( 4 , 8 ), : score =  1.0\nHidden layer size : ( 4 , 9 ), : score =  1.0\nHidden layer size : ( 4 , 10 ), : score =  1.0\nHidden layer size : ( 5 , 3 ), : score =  1.0\nHidden layer size : ( 5 , 4 ), : score =  1.0\nHidden layer size : ( 5 , 6 ), : score =  1.0\nHidden layer size : ( 5 , 7 ), : score =  1.0\nHidden layer size : ( 5 , 8 ), : score =  1.0\nHidden layer size : ( 5 , 9 ), : score =  1.0\nHidden layer size : ( 6 , 2 ), : score =  1.0\nHidden layer size : ( 6 , 4 ), : score =  1.0\nHidden layer size : ( 6 , 6 ), : score =  1.0\nHidden layer size : ( 6 , 7 ), : score =  1.0\nHidden layer size : ( 6 , 8 ), : score =  1.0\nHidden layer size : ( 6 , 10 ), : score =  1.0\nHidden layer size : ( 7 , 3 ), : score =  1.0\nHidden layer size : ( 7 , 4 ), : score =  1.0\nHidden layer size : ( 7 , 5 ), : score =  1.0\nHidden layer size : ( 7 , 6 ), : score =  1.0\nHidden layer size : ( 7 , 7 ), : score =  1.0\nHidden layer size : ( 7 , 8 ), : score =  1.0\nHidden layer size : ( 7 , 9 ), : score =  1.0\nHidden layer size : ( 7 , 10 ), : score =  1.0\nHidden layer size : ( 8 , 4 ), : score =  1.0\nHidden layer size : ( 8 , 9 ), : score =  1.0\nHidden layer size : ( 8 , 10 ), : score =  1.0\nHidden layer size : ( 9 , 3 ), : score =  1.0\nHidden layer size : ( 9 , 4 ), : score =  1.0\nHidden layer size : ( 9 , 6 ), : score =  1.0\nHidden layer size : ( 9 , 7 ), : score =  1.0\nHidden layer size : ( 9 , 8 ), : score =  1.0\nHidden layer size : ( 10 , 5 ), : score =  1.0\nHidden layer size : ( 10 , 7 ), : score =  1.0\nHidden layer size : ( 10 , 8 ), : score =  1.0\nHidden layer size : ( 10 , 9 ), : score =  1.0\nHidden layer size : ( 10 , 10 ), : score =  1.0\nBest Hidden layer size : ( 1 , 2 ), : score =  1.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "clf.predict_proba(X_test)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 17,
      "outputs": [
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[1.00000000e+000, 3.00551256e-026, 1.32042901e-040],\n       [9.99163249e-032, 9.99999735e-001, 2.65083783e-007],\n       [2.89748523e-061, 9.99971699e-001, 2.83007119e-005],\n       [1.00000000e+000, 1.71078719e-020, 2.96154387e-032],\n       [1.49982880e-125, 9.09733686e-005, 9.99909027e-001],\n       [1.27822685e-070, 9.98795942e-001, 1.20405783e-003],\n       [2.54110045e-118, 3.87254670e-005, 9.99961275e-001],\n       [1.00000000e+000, 1.49498258e-013, 2.62515583e-024],\n       [1.00000000e+000, 1.91613081e-020, 9.06314850e-032],\n       [3.93546879e-133, 3.07207521e-007, 9.99999693e-001],\n       [4.47392559e-055, 9.99976331e-001, 2.36690786e-005],\n       [1.00000000e+000, 1.52739485e-015, 1.94086747e-026],\n       [1.06260700e-131, 8.54255083e-007, 9.99999146e-001],\n       [4.89989520e-064, 9.99904708e-001, 9.52916435e-005],\n       [2.47460593e-067, 9.99081939e-001, 9.18061380e-004]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "We got a score of 1.0 on the Neueral Network model. This means that the model did a perfect job at classifying the different iris classes given the different feature values. The score measures the percent of times it correctly predicted a iris' class.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## K Nearest Neighbor",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# K NEAREST NEIGHBOR ORINIAL\nfor i in range(1,11): # test knn with k ranging from 1-10\n    clf = KNeighborsClassifier(n_neighbors=i)\n    clf.fit(X, Y)\n    print(i, \" Nearest Neighbors : score =\",clf.score(X, Y))",
      "metadata": {
        "trusted": true
      },
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "text": "1  Nearest Neighbors : score = 1.0\n2  Nearest Neighbors : score = 0.98\n3  Nearest Neighbors : score = 0.96\n4  Nearest Neighbors : score = 0.96\n5  Nearest Neighbors : score = 0.9666666666666667\n6  Nearest Neighbors : score = 0.9733333333333334\n7  Nearest Neighbors : score = 0.9733333333333334\n8  Nearest Neighbors : score = 0.98\n9  Nearest Neighbors : score = 0.98\n10  Nearest Neighbors : score = 0.98\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# K NEAREST NEIGHBOR SPLIT\nfor i in range(1,11): # test knn with k ranging from 1-10\n    clf = KNeighborsClassifier(n_neighbors=i)\n    clf.fit(X_train, Y_train)\n    print(i, \" Nearest Neighbors : score =\",clf.score(X_test, Y_test))",
      "metadata": {
        "trusted": true
      },
      "execution_count": 19,
      "outputs": [
        {
          "name": "stdout",
          "text": "1  Nearest Neighbors : score = 1.0\n2  Nearest Neighbors : score = 1.0\n3  Nearest Neighbors : score = 1.0\n4  Nearest Neighbors : score = 1.0\n5  Nearest Neighbors : score = 1.0\n6  Nearest Neighbors : score = 1.0\n7  Nearest Neighbors : score = 1.0\n8  Nearest Neighbors : score = 1.0\n9  Nearest Neighbors : score = 1.0\n10  Nearest Neighbors : score = 1.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "clf = KNeighborsClassifier(n_neighbors=1)\nclf.fit(X_train, Y_train)\nclf.predict_proba(X_test)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 20,
      "outputs": [
        {
          "execution_count": 20,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[1., 0., 0.],\n       [0., 1., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 0., 1.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       [0., 0., 1.],\n       [0., 1., 0.],\n       [0., 1., 0.]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "We got a score of 1.0 on the K Nearest Nieghbor model with a value of k. This means that the model did a perfect job at classifying the different iris classes given the different feature values. The score measures the percent of times it correctly predicted a iris' class. The second best k value is 2 with a score .98 meaning it correctly classified the sample 98% of the time",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Conclution and Takeaways\nI noticed that all of models performed well in classifying the iris dataset, as their scores were almost always perfect (1.0). I did find it all that the scores were so well, but this can be due to the fact that there isn't a lot of data in the set. Especially, when the data is split up 9:1 of training to test data, we are only predicting 15 samples, therefore it is more liekly to get better scores on smaller test sizes. As an alternative I also calculated the score based on the original dataset without any splitting. In regards to the split data(X_train, X_test, Y_train, Y_test), the best model is KNN where k =1 because it is the simplest model, in that it doesnt require \"training\" while still maintaining a perfect score. In regards to the oriniginal data ( the unsplit datat), the best model would also be KNN where k =1 as it has a perfect score. The second best option would be neural nets with hidden layer (1,2) as it has a score of .993333 ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}